{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 dict_keys(['prompt_text', 'prompt_token_ids', 'prompt_attention_mask', 'token_ids', 'token_pattern_matrices'])\n"
     ]
    }
   ],
   "source": [
    "data = torch.load('pattern_matrices.pt')\n",
    "print(len(data), data[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 统计数据集信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. prompt 统计信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 382, 65.696, 30.360823177246033)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_lens = np.array([len(sample['prompt_token_ids']) for sample in data.values()])\n",
    "prompt_lens.min(), prompt_lens.max(), prompt_lens.mean(), prompt_lens.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. decoding 统计信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(64, 64, 64.0, 0.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoding_tokens = []\n",
    "for i in range(len(data)):\n",
    "    sample = data[i]\n",
    "    decoding_tokens.append(sample['token_ids'][prompt_lens[i]:])\n",
    "decoding_tokens = torch.stack(decoding_tokens)\n",
    "print(decoding_tokens.shape)\n",
    "decoding_token_lens = np.array([len(x) for x in decoding_tokens])\n",
    "decoding_token_lens.min(), decoding_token_lens.max(), decoding_token_lens.mean(), decoding_token_lens.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2000, 63, 32, 8]),\n",
       " torch.Size([63, 32, 8]),\n",
       " tensor([[1., 0., 0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 1., 0.],\n",
       "         [0., 0., 0., 0., 1., 1., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 1., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0., 1., 0.],\n",
       "         [0., 0., 1., 0., 1., 0., 0., 0.],\n",
       "         [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 1., 0.],\n",
       "         [1., 0., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 1., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 1., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 1., 0.],\n",
       "         [0., 0., 0., 0., 1., 0., 0., 1.],\n",
       "         [0., 1., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "         [1., 0., 0., 0., 0., 0., 1., 0.],\n",
       "         [1., 0., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "         [0., 0., 0., 1., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 1., 0.],\n",
       "         [0., 0., 1., 0., 0., 1., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 1., 1., 0., 0.],\n",
       "         [1., 0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 1.]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoding_token_pattern_matrices = []\n",
    "for i in range(len(data)):\n",
    "    sample = data[i]\n",
    "    decoding_token_pattern_matrices.append(sample['token_pattern_matrices'][prompt_lens[i]:]) # (#decoding_tokens, #layers, #experts)\n",
    "decoding_token_pattern_matrices = torch.stack(decoding_token_pattern_matrices)\n",
    "decoding_token_pattern_matrices.shape, decoding_token_pattern_matrices[0].shape, decoding_token_pattern_matrices[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建 Predictor 训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt_text', 'prompt_tokens_len', 'token_ids', 'token_pattern_matrices'],\n",
       "    num_rows: 2000\n",
       "})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "hf_data = {\n",
    "    'prompt_text': [],\n",
    "    'prompt_tokens_len': [],\n",
    "    'token_ids': [],\n",
    "    # 'prompt_token_ids': [],\n",
    "    # 'decoding_token_ids': [],\n",
    "    'token_pattern_matrices': []\n",
    "}\n",
    "\n",
    "# for i in range(10):\n",
    "for i in range(len(data)):\n",
    "    sample = data[i]\n",
    "    prompt_text = sample['prompt_text']\n",
    "    padded_prompt_token_ids = sample['prompt_token_ids']\n",
    "    prompt_attention_mask = sample['prompt_attention_mask']\n",
    "    start_index = prompt_attention_mask.argmax().item()\n",
    "    token_ids = sample['token_ids'][start_index:-1]\n",
    "    prompt_token_ids = padded_prompt_token_ids[start_index:]\n",
    "    prompt_tokens_len = len(prompt_token_ids)\n",
    "    decoding_token_ids = sample['token_ids'][len(prompt_attention_mask):-1]\n",
    "    token_pattern_matrices = sample['token_pattern_matrices'][start_index:]\n",
    "    assert len(token_ids)==len(decoding_token_ids)+len(prompt_token_ids)\n",
    "    assert token_ids.numpy().tolist()==prompt_token_ids.numpy().tolist()+decoding_token_ids.numpy().tolist()\n",
    "    assert len(token_pattern_matrices)==len(token_ids)\n",
    "    hf_data['prompt_text'].append(prompt_text)\n",
    "    hf_data['prompt_tokens_len'].append(prompt_tokens_len)\n",
    "    hf_data['token_ids'].append(token_ids)\n",
    "    # hf_data['prompt_token_ids'].append(prompt_token_ids)\n",
    "    # hf_data['decoding_token_ids'].append(decoding_token_ids)\n",
    "    hf_data['token_pattern_matrices'].append(token_pattern_matrices)\n",
    "hf_data = Dataset.from_dict(hf_data)\n",
    "hf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([382]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " tensor(382),\n",
       " 0,\n",
       " torch.Size([63]),\n",
       " torch.Size([445]),\n",
       " torch.Size([445, 32, 8]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_token_ids.shape, prompt_attention_mask, prompt_attention_mask.sum(), prompt_attention_mask.argmax().item(), decoding_token_ids.shape, token_ids.shape, token_pattern_matrices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 2/2 [00:01<00:00,  1.08ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:04<00:00,  4.94s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/marsggbo/mixtral_8x7b_moe_alpaca_2k_token_pattern/commit/2fc2ba69bd0cf6b5f5dba433d10f5641ba53048f', commit_message='Upload dataset', commit_description='', oid='2fc2ba69bd0cf6b5f5dba433d10f5641ba53048f', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_data.push_to_hub('marsggbo/mixtral_8x7b_moe_alpaca_2k_token_pattern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 459/459 [00:00<00:00, 4.31MB/s]\n",
      "Downloading data: 100%|██████████| 8.02M/8.02M [00:00<00:00, 8.42MB/s]\n",
      "Generating train split: 100%|██████████| 2000/2000 [00:01<00:00, 1911.88 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prompt_text', 'prompt_tokens_len', 'token_ids', 'token_pattern_matrices'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"marsggbo/mixtral_8x7b_moe_alpaca_2k_token_pattern\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 382 59.2955 21.39596176267849\n"
     ]
    }
   ],
   "source": [
    "lens = [x for x in dataset['train']['prompt_tokens_len']]\n",
    "print(np.min(lens), np.max(lens), np.mean(lens), np.std(lens))\n",
    "# lens = [len(x) for x in dataset['test']['prompt_token_ids']]\n",
    "# print(np.min(lens), np.max(lens), np.mean(lens), np.std(lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "typing.Union[str, datasets.arrow_dataset.Dataset]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from typing import List, Optional, Tuple, Union\n",
    "Union[str, Dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, (102, 32, 8))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = dataset['train'][0]\n",
    "prompt_tokens_len = sample['prompt_tokens_len']\n",
    "len(sample['token_ids'][:prompt_tokens_len]), np.stack(sample['token_pattern_matrices']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 1, 0,  ..., 1, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 1, 0,  ..., 0, 0, 1],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 1, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 1,  ..., 0, 0, 1]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 1, 1, 0],\n",
       "         [1, 0, 1,  ..., 0, 0, 0],\n",
       "         [0, 0, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 1, 0],\n",
       "         [0, 0, 1,  ..., 0, 0, 0],\n",
       "         [1, 0, 0,  ..., 0, 1, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 1, 1, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 1],\n",
       "         [0, 0, 0,  ..., 1, 0, 0],\n",
       "         ...,\n",
       "         [1, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 1, 0],\n",
       "         [0, 0, 1,  ..., 0, 1, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 1,  ..., 1, 0, 0],\n",
       "         [0, 0, 1,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 1, 1],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 1, 0, 0],\n",
       "         [0, 1, 0,  ..., 0, 1, 0],\n",
       "         [0, 0, 0,  ..., 0, 1, 0]],\n",
       "\n",
       "        [[1, 0, 0,  ..., 0, 0, 1],\n",
       "         [0, 0, 0,  ..., 1, 0, 1],\n",
       "         [1, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 1, 0, 1],\n",
       "         [0, 0, 0,  ..., 0, 0, 1],\n",
       "         [0, 0, 1,  ..., 0, 0, 1]],\n",
       "\n",
       "        [[0, 0, 1,  ..., 1, 0, 0],\n",
       "         [0, 0, 0,  ..., 1, 0, 1],\n",
       "         [1, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 1, 0,  ..., 0, 0, 1],\n",
       "         [0, 0, 1,  ..., 0, 0, 1],\n",
       "         [1, 0, 0,  ..., 0, 0, 0]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.stack(sample['token_pattern_matrices'])\n",
    "labels = torch.from_numpy(labels).int()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    1, 20811,   349,   396, 13126,   369, 13966,   264,  3638, 28723,\n",
       "        12018,   264,  2899,   369,  6582,  1999,  2691,   274,   272,  2159,\n",
       "        28723,    13,    13, 27332,  3133,  3112, 28747,    13, 28784,   648,\n",
       "        28705, 28770,   327,  1550,    13,    13, 27332, 12107, 28747,    13,\n",
       "        28784,   648, 28705, 28770, 21588, 28705, 28774, 28723,     2, 10020,\n",
       "        28744,     2, 10020, 28744,    13,    13, 27332, 11530, 12107, 28747,\n",
       "           13, 28774, 28723,     2, 10020, 28744,     2, 10020, 28744,    13,\n",
       "           13, 27332,  1529, 11009,   352, 28747,    13,  7477,   368,   967,\n",
       "        28705, 28784,   304, 28705, 28770,  2553, 28725,   368,   625, 28705,\n",
       "        28774, 28723,   415,  1474, 28705, 28774,   349,   272,  2648,   302,\n",
       "        28705, 28784])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(sample['token_ids'], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_precision_recall_f1(y_true_origin, y_pred_origin):\n",
    "    bs, seq_len, num_layer, num_experts = y_true_origin.shape\n",
    "    y_true = np.reshape(y_true_origin, (bs, seq_len, num_layer * num_experts))\n",
    "    y_pred = np.reshape(y_pred_origin, (bs, seq_len, num_layer * num_experts))\n",
    "    y_true = np.transpose(y_true, (1, 0, 2)) # (seq, bs, num_layer * num_experts)\n",
    "    y_pred = np.transpose(y_pred, (1, 0, 2)) # (seq, bs, num_layer * num_experts)\n",
    "    y_true = (y_true.sum(1)>0).astype(int) # (seq, num_layer * num_experts)\n",
    "    y_pred = (y_pred.sum(1)>0).astype(int) # (seq, num_layer * num_experts)\n",
    "    print(y_true.shape, y_true)\n",
    "    # 真正例 (True Positives)\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    \n",
    "    # 假正例 (False Positives)\n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    \n",
    "    # 假负例 (False Negatives)\n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    \n",
    "    # 真负例 (True Negatives)\n",
    "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
    "\n",
    "    y_true = y_true.reshape(-1, 256)\n",
    "    y_pred = y_pred.reshape(-1, 256)\n",
    "    print(f\"origin y_true.shape={y_true.shape}\")\n",
    "    indices = np.any(y_true, axis=-1)\n",
    "    print(indices.shape)\n",
    "    y_true = y_true[indices]\n",
    "    y_pred = y_pred[indices]\n",
    "    print(f\"filtered y_true.shape={y_true.shape}\")\n",
    "\n",
    "    # 准确率\n",
    "    num_tokens = y_true.shape[0]\n",
    "    accuracy = TP / (num_tokens*64)\n",
    "    recall = 0\n",
    "    precision = 0\n",
    "    f1 = 0\n",
    "    print(f\"non-padding ratio: {indices.sum()}/{len(indices)}={indices.sum()/len(indices)}\\n\")\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'recall': recall,\n",
    "        'precision': precision,\n",
    "        'f1': f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 256) [[1 1 1 ... 1 1 1]\n",
      " [1 1 0 ... 1 1 1]\n",
      " [1 1 1 ... 1 1 1]\n",
      " ...\n",
      " [0 1 1 ... 1 1 0]\n",
      " [1 1 1 ... 1 1 1]\n",
      " [1 1 1 ... 1 1 1]]\n",
      "origin y_true.shape=(8, 256)\n",
      "(8,)\n",
      "filtered y_true.shape=(8, 256)\n",
      "non-padding ratio: 8/8=1.0\n",
      "\n",
      "{'accuracy': 3.46875, 'recall': 0, 'precision': 0, 'f1': 0}\n"
     ]
    }
   ],
   "source": [
    "seq_len = 12\n",
    "pad_seq_len = 4 \n",
    "y_true = torch.randint(0,2,(4,8,32,8)).numpy()\n",
    "y_pred = torch.randint(0,2,(4,8,32,8)).numpy()\n",
    "print(acc_precision_recall_f1(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = {\n",
    "    \"auto_categorization\": 328,\n",
    "    \"tense\": 286,\n",
    "    \"disfl_qa\": 8000,\n",
    "    \"semantic_parsing_in_context_sparc\": 1160,\n",
    "    \"word_sorting\": 1900,\n",
    "    \"linguistics_puzzles\": 2000,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto_categorization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nus-hx/.conda/envs/moe/lib/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for tasksource/bigbench contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/tasksource/bigbench\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tense\n",
      "disfl_qa\n",
      "semantic_parsing_in_context_sparc\n",
      "word_sorting\n",
      "linguistics_puzzles\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "dataset_name = \"tasksource/bigbench\"\n",
    "# names = datasets.get_dataset_config_names(dataset_name)\n",
    "\n",
    "names = list(dataset_names.keys())\n",
    "all_inputs = []\n",
    "for name in names:\n",
    "    print(name)\n",
    "    all_inputs.append(datasets.load_dataset(dataset_name, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['inputs', 'targets', 'multiple_choice_targets', 'multiple_choice_scores', 'idx'],\n",
       "        num_rows: 263\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['inputs', 'targets', 'multiple_choice_targets', 'multiple_choice_scores', 'idx'],\n",
       "        num_rows: 65\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10936, 2733)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_all_inputs = []\n",
    "valid_all_inputs = []\n",
    "for dataset in all_inputs:\n",
    "    train_all_inputs += [text for text in dataset[\"train\"][\"inputs\"]]\n",
    "    valid_all_inputs += [text for text in dataset[\"validation\"][\"inputs\"]]\n",
    "len(train_all_inputs), len(valid_all_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nus-hx/.conda/envs/moe/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt_text', 'prompt_ids', 'decode_ids', 'prompt_pattern', 'decode_pattern'],\n",
       "    num_rows: 10936\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(\"marsggbo/bigbench4switch64_pattern_predictor\")['train']\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(dataset[0]['decode_pattern']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-t5/t5-base\")\n",
    "tokenizer.padding_side = 'left'\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google-t5/t5-base\")\n",
    "model.lm_head = torch.nn.Linear(768, 6*64)\n",
    "model = model.cuda(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(transformers.models.t5.modeling_t5.T5ForConditionalGeneration, 768)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__class__, model.config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "425.718017578125"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = sum([p.numel() for p in model.parameters()])\n",
    "params*2/1024**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.2365039348602295,\n",
       " 2: 0.2400728702545166,\n",
       " 3: 0.24014568328857422,\n",
       " 4: 0.24187352657318115,\n",
       " 5: 0.2428675889968872,\n",
       " 6: 0.24388659000396729,\n",
       " 7: 0.2439492702484131,\n",
       " 8: 0.2441192626953125,\n",
       " 9: 0.24286985397338867,\n",
       " 10: 0.24423601627349853,\n",
       " 11: 0.24433786869049073,\n",
       " 12: 0.24466307163238527,\n",
       " 13: 0.24510047435760499,\n",
       " 14: 0.2453702926635742,\n",
       " 15: 0.24580740928649902}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "decoder_lens = list(range(1, 16))\n",
    "bs = 32\n",
    "encoder_len = 512\n",
    "device = torch.device(\"cuda:1\")\n",
    "time_costs = {}\n",
    "# warmup\n",
    "\n",
    "input_ids = torch.randint(0, 100, (bs, encoder_len)).to(device)\n",
    "attention_mask = torch.ones(bs, encoder_len).to(device)\n",
    "decoder_input_ids =torch.randint(0, 100, (bs, 10)).to(device)\n",
    "out = model(\n",
    "    input_ids=input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    decoder_input_ids=decoder_input_ids,\n",
    ")\n",
    "\n",
    "for decoder_len in decoder_lens:\n",
    "    input_ids = torch.randint(0, 100, (bs, encoder_len)).to(device)\n",
    "    attention_mask = torch.ones(bs, encoder_len).to(device)\n",
    "    decoder_input_ids =torch.randint(0, 100, (bs, decoder_len)).to(device)\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.time()\n",
    "    for i in range(10):\n",
    "        out = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "        )\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    time_costs[decoder_len] = (end-start)/10\n",
    "time_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 32, 384]) tensor(0.6928, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([8, 32, 384]) tensor(0.6928, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([8, 32, 384]) tensor(0.6927, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "torch.Size([8, 32, 384]) tensor(0.6928, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    }
   ],
   "source": [
    "bs = 32\n",
    "batch_indices = [list(range(i,i+bs)) for i in range(0, len(dataset), bs)]\n",
    "all_prompt_text = np.array(dataset['prompt_text'])\n",
    "all_decode_ids = np.array(dataset['decode_ids'])\n",
    "all_decode_pattern = np.array(dataset['decode_pattern'])\n",
    "num_experts_per_layer = 64\n",
    "for indices in batch_indices[:4]:\n",
    "    batch_text = all_prompt_text[indices].tolist()\n",
    "    data = tokenizer(batch_text, return_tensors=\"pt\", return_attention_mask=True, padding=True)\n",
    "    input_ids = data.input_ids.cuda()\n",
    "    attention_mask = data.attention_mask.cuda()\n",
    "    decoder_input_ids = torch.tensor(all_decode_ids[indices]).cuda()\n",
    "    decode_pattern = torch.tensor(all_decode_pattern[indices]).permute(0,2,1).cuda()\n",
    "    decode_pattern = torch.nn.functional.one_hot(decode_pattern, num_classes=num_experts_per_layer).float()\n",
    "    out = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        decoder_input_ids=decoder_input_ids,\n",
    "    )\n",
    "    logits = out.logits\n",
    "    loss = torch.nn.functional.binary_cross_entropy_with_logits(\n",
    "            logits.view(-1, num_experts_per_layer),\n",
    "            decode_pattern.view(-1, num_experts_per_layer),\n",
    "            reduction='mean')\n",
    "    print(out.logits.shape, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 32, 32128])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 32, 6]), torch.Size([8, 32]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_pattern.shape, decoding_token_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 0, 0, 0, 5, 4],\n",
       "         [6, 5, 4, 3, 2, 1]]),\n",
       " tensor([[False, False, False, False,  True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True]]),\n",
       " tensor([[1, 2, 0, 0, 0, 0],\n",
       "         [3, 4, 5, 6, 7, 8]]),\n",
       " tensor([[ True,  True, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def prepare_batch(input_seqs, target_seqs, pad_token_id=0):\n",
    "    # 输入和目标序列的填充\n",
    "    input_padded = torch.nn.utils.rnn.pad_sequence(\n",
    "        input_seqs[::-1], batch_first=True, padding_value=pad_token_id).flip(dims=[1])\n",
    "    target_padded = torch.nn.utils.rnn.pad_sequence(\n",
    "        target_seqs, batch_first=True, padding_value=pad_token_id)\n",
    "\n",
    "    # 创建编码器和解码器的掩码\n",
    "    input_mask = (input_padded != pad_token_id)\n",
    "    target_mask = (target_padded != pad_token_id)\n",
    "\n",
    "    return input_padded, input_mask, target_padded, target_mask\n",
    "\n",
    "# 假设 input_seqs 和 target_seqs 是预处理后的序列列表，其中每个元素是一个tensor\n",
    "input_seqs = [torch.tensor([1, 2, 3, 4, 5, 6]), torch.tensor([4, 5])]\n",
    "target_seqs = [torch.tensor([1, 2]), torch.tensor([3, 4, 5, 6, 7, 8])]\n",
    "\n",
    "input_padded, input_mask, target_padded, target_mask = prepare_batch(input_seqs, target_seqs)\n",
    "(input_padded.shape, input_mask.shape, target_padded.shape, target_mask.shape)\n",
    "(input_padded, input_mask, target_padded, target_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([9]), torch.Size([3])]\n",
      "torch.Size([2, 9]) tensor([[52, 96, 67, 19, 30, 99, 36, 52, 34],\n",
      "        [55, 53, 64,  0,  0,  0,  0,  0,  0]])\n",
      "[torch.Size([9, 16]), torch.Size([3, 16])]\n",
      "torch.Size([2, 9, 16])\n"
     ]
    }
   ],
   "source": [
    "bs=2\n",
    "seq_len = torch.randint(1, 10, (bs,))\n",
    "target_seqs = [torch.randint(0,100,(seq_len[i], )) for i in range(bs)]\n",
    "pad_target_seqs = torch.nn.utils.rnn.pad_sequence(target_seqs, batch_first=True, padding_value=0)\n",
    "print([x.shape for x in target_seqs])\n",
    "print(pad_target_seqs.shape, pad_target_seqs)\n",
    "\n",
    "\n",
    "labels = [torch.randint(0, 2, (seq_len[i], 16)) for i in range(bs)]\n",
    "print([x.shape for x in labels])\n",
    "pad_labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=0)\n",
    "print(pad_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1],\n",
       "        [0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0],\n",
       "        [0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
