{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 dict_keys(['prompt_text', 'prompt_token_ids', 'prompt_attention_mask', 'token_ids', 'token_pattern_matrices'])\n"
     ]
    }
   ],
   "source": [
    "data = torch.load('pattern_matrices.pt')\n",
    "print(len(data), data[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 统计数据集信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. prompt 统计信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 382, 65.696, 30.360823177246033)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_lens = np.array([len(sample['prompt_token_ids']) for sample in data.values()])\n",
    "prompt_lens.min(), prompt_lens.max(), prompt_lens.mean(), prompt_lens.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. decoding 统计信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(64, 64, 64.0, 0.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoding_tokens = []\n",
    "for i in range(len(data)):\n",
    "    sample = data[i]\n",
    "    decoding_tokens.append(sample['token_ids'][prompt_lens[i]:])\n",
    "decoding_tokens = torch.stack(decoding_tokens)\n",
    "print(decoding_tokens.shape)\n",
    "decoding_token_lens = np.array([len(x) for x in decoding_tokens])\n",
    "decoding_token_lens.min(), decoding_token_lens.max(), decoding_token_lens.mean(), decoding_token_lens.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2000, 63, 32, 8]),\n",
       " torch.Size([63, 32, 8]),\n",
       " tensor([[1., 0., 0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 1., 0.],\n",
       "         [0., 0., 0., 0., 1., 1., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 1., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0., 1., 0.],\n",
       "         [0., 0., 1., 0., 1., 0., 0., 0.],\n",
       "         [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 1., 0.],\n",
       "         [1., 0., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 1., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 1., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 1., 0.],\n",
       "         [0., 0., 0., 0., 1., 0., 0., 1.],\n",
       "         [0., 1., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "         [1., 0., 0., 0., 0., 0., 1., 0.],\n",
       "         [1., 0., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "         [0., 0., 0., 1., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 1., 0.],\n",
       "         [0., 0., 1., 0., 0., 1., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 1., 1., 0., 0.],\n",
       "         [1., 0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 1.]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoding_token_pattern_matrices = []\n",
    "for i in range(len(data)):\n",
    "    sample = data[i]\n",
    "    decoding_token_pattern_matrices.append(sample['token_pattern_matrices'][prompt_lens[i]:]) # (#decoding_tokens, #layers, #experts)\n",
    "decoding_token_pattern_matrices = torch.stack(decoding_token_pattern_matrices)\n",
    "decoding_token_pattern_matrices.shape, decoding_token_pattern_matrices[0].shape, decoding_token_pattern_matrices[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建 Predictor 训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt_text', 'prompt_tokens_len', 'token_ids', 'token_pattern_matrices'],\n",
       "    num_rows: 2000\n",
       "})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "hf_data = {\n",
    "    'prompt_text': [],\n",
    "    'prompt_tokens_len': [],\n",
    "    'token_ids': [],\n",
    "    # 'prompt_token_ids': [],\n",
    "    # 'decoding_token_ids': [],\n",
    "    'token_pattern_matrices': []\n",
    "}\n",
    "\n",
    "# for i in range(10):\n",
    "for i in range(len(data)):\n",
    "    sample = data[i]\n",
    "    prompt_text = sample['prompt_text']\n",
    "    padded_prompt_token_ids = sample['prompt_token_ids']\n",
    "    prompt_attention_mask = sample['prompt_attention_mask']\n",
    "    start_index = prompt_attention_mask.argmax().item()\n",
    "    token_ids = sample['token_ids'][start_index:-1]\n",
    "    prompt_token_ids = padded_prompt_token_ids[start_index:]\n",
    "    prompt_tokens_len = len(prompt_token_ids)\n",
    "    decoding_token_ids = sample['token_ids'][len(prompt_attention_mask):-1]\n",
    "    token_pattern_matrices = sample['token_pattern_matrices'][start_index:]\n",
    "    assert len(token_ids)==len(decoding_token_ids)+len(prompt_token_ids)\n",
    "    assert token_ids.numpy().tolist()==prompt_token_ids.numpy().tolist()+decoding_token_ids.numpy().tolist()\n",
    "    assert len(token_pattern_matrices)==len(token_ids)\n",
    "    hf_data['prompt_text'].append(prompt_text)\n",
    "    hf_data['prompt_tokens_len'].append(prompt_tokens_len)\n",
    "    hf_data['token_ids'].append(token_ids)\n",
    "    # hf_data['prompt_token_ids'].append(prompt_token_ids)\n",
    "    # hf_data['decoding_token_ids'].append(decoding_token_ids)\n",
    "    hf_data['token_pattern_matrices'].append(token_pattern_matrices)\n",
    "hf_data = Dataset.from_dict(hf_data)\n",
    "hf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([382]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " tensor(382),\n",
       " 0,\n",
       " torch.Size([63]),\n",
       " torch.Size([445]),\n",
       " torch.Size([445, 32, 8]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_token_ids.shape, prompt_attention_mask, prompt_attention_mask.sum(), prompt_attention_mask.argmax().item(), decoding_token_ids.shape, token_ids.shape, token_pattern_matrices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 2/2 [00:01<00:00,  1.08ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:04<00:00,  4.94s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/marsggbo/mixtral_8x7b_moe_alpaca_2k_token_pattern/commit/2fc2ba69bd0cf6b5f5dba433d10f5641ba53048f', commit_message='Upload dataset', commit_description='', oid='2fc2ba69bd0cf6b5f5dba433d10f5641ba53048f', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_data.push_to_hub('marsggbo/mixtral_8x7b_moe_alpaca_2k_token_pattern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 459/459 [00:00<00:00, 4.31MB/s]\n",
      "Downloading data: 100%|██████████| 8.02M/8.02M [00:00<00:00, 8.42MB/s]\n",
      "Generating train split: 100%|██████████| 2000/2000 [00:01<00:00, 1911.88 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prompt_text', 'prompt_tokens_len', 'token_ids', 'token_pattern_matrices'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"marsggbo/mixtral_8x7b_moe_alpaca_2k_token_pattern\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 382 59.2955 21.39596176267849\n"
     ]
    }
   ],
   "source": [
    "lens = [x for x in dataset['train']['prompt_tokens_len']]\n",
    "print(np.min(lens), np.max(lens), np.mean(lens), np.std(lens))\n",
    "# lens = [len(x) for x in dataset['test']['prompt_token_ids']]\n",
    "# print(np.min(lens), np.max(lens), np.mean(lens), np.std(lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "typing.Union[str, datasets.arrow_dataset.Dataset]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from typing import List, Optional, Tuple, Union\n",
    "Union[str, Dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, (102, 32, 8))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = dataset['train'][0]\n",
    "prompt_tokens_len = sample['prompt_tokens_len']\n",
    "len(sample['token_ids'][:prompt_tokens_len]), np.stack(sample['token_pattern_matrices']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 1, 0,  ..., 1, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 1, 0,  ..., 0, 0, 1],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 1, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 1,  ..., 0, 0, 1]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 1, 1, 0],\n",
       "         [1, 0, 1,  ..., 0, 0, 0],\n",
       "         [0, 0, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 1, 0],\n",
       "         [0, 0, 1,  ..., 0, 0, 0],\n",
       "         [1, 0, 0,  ..., 0, 1, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 1, 1, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 1],\n",
       "         [0, 0, 0,  ..., 1, 0, 0],\n",
       "         ...,\n",
       "         [1, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 1, 0],\n",
       "         [0, 0, 1,  ..., 0, 1, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 1,  ..., 1, 0, 0],\n",
       "         [0, 0, 1,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 1, 1],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 1, 0, 0],\n",
       "         [0, 1, 0,  ..., 0, 1, 0],\n",
       "         [0, 0, 0,  ..., 0, 1, 0]],\n",
       "\n",
       "        [[1, 0, 0,  ..., 0, 0, 1],\n",
       "         [0, 0, 0,  ..., 1, 0, 1],\n",
       "         [1, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 1, 0, 1],\n",
       "         [0, 0, 0,  ..., 0, 0, 1],\n",
       "         [0, 0, 1,  ..., 0, 0, 1]],\n",
       "\n",
       "        [[0, 0, 1,  ..., 1, 0, 0],\n",
       "         [0, 0, 0,  ..., 1, 0, 1],\n",
       "         [1, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 1, 0,  ..., 0, 0, 1],\n",
       "         [0, 0, 1,  ..., 0, 0, 1],\n",
       "         [1, 0, 0,  ..., 0, 0, 0]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.stack(sample['token_pattern_matrices'])\n",
    "labels = torch.from_numpy(labels).int()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    1, 20811,   349,   396, 13126,   369, 13966,   264,  3638, 28723,\n",
       "        12018,   264,  2899,   369,  6582,  1999,  2691,   274,   272,  2159,\n",
       "        28723,    13,    13, 27332,  3133,  3112, 28747,    13, 28784,   648,\n",
       "        28705, 28770,   327,  1550,    13,    13, 27332, 12107, 28747,    13,\n",
       "        28784,   648, 28705, 28770, 21588, 28705, 28774, 28723,     2, 10020,\n",
       "        28744,     2, 10020, 28744,    13,    13, 27332, 11530, 12107, 28747,\n",
       "           13, 28774, 28723,     2, 10020, 28744,     2, 10020, 28744,    13,\n",
       "           13, 27332,  1529, 11009,   352, 28747,    13,  7477,   368,   967,\n",
       "        28705, 28784,   304, 28705, 28770,  2553, 28725,   368,   625, 28705,\n",
       "        28774, 28723,   415,  1474, 28705, 28774,   349,   272,  2648,   302,\n",
       "        28705, 28784])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(sample['token_ids'], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_precision_recall_f1(y_true_origin, y_pred_origin):\n",
    "    bs, seq_len, num_layer, num_experts = y_true_origin.shape\n",
    "    y_true = np.reshape(y_true_origin, (bs, seq_len, num_layer * num_experts))\n",
    "    y_pred = np.reshape(y_pred_origin, (bs, seq_len, num_layer * num_experts))\n",
    "    y_true = np.transpose(y_true, (1, 0, 2)) # (seq, bs, num_layer * num_experts)\n",
    "    y_pred = np.transpose(y_pred, (1, 0, 2)) # (seq, bs, num_layer * num_experts)\n",
    "    y_true = (y_true.sum(1)>0).astype(int) # (seq, num_layer * num_experts)\n",
    "    y_pred = (y_pred.sum(1)>0).astype(int) # (seq, num_layer * num_experts)\n",
    "    print(y_true.shape, y_true)\n",
    "    # 真正例 (True Positives)\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    \n",
    "    # 假正例 (False Positives)\n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    \n",
    "    # 假负例 (False Negatives)\n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    \n",
    "    # 真负例 (True Negatives)\n",
    "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
    "\n",
    "    y_true = y_true.reshape(-1, 256)\n",
    "    y_pred = y_pred.reshape(-1, 256)\n",
    "    print(f\"origin y_true.shape={y_true.shape}\")\n",
    "    indices = np.any(y_true, axis=-1)\n",
    "    print(indices.shape)\n",
    "    y_true = y_true[indices]\n",
    "    y_pred = y_pred[indices]\n",
    "    print(f\"filtered y_true.shape={y_true.shape}\")\n",
    "\n",
    "    # 准确率\n",
    "    num_tokens = y_true.shape[0]\n",
    "    accuracy = TP / (num_tokens*64)\n",
    "    recall = 0\n",
    "    precision = 0\n",
    "    f1 = 0\n",
    "    print(f\"non-padding ratio: {indices.sum()}/{len(indices)}={indices.sum()/len(indices)}\\n\")\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'recall': recall,\n",
    "        'precision': precision,\n",
    "        'f1': f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 256) [[1 1 1 ... 1 1 1]\n",
      " [1 1 0 ... 1 1 1]\n",
      " [1 1 1 ... 1 1 1]\n",
      " ...\n",
      " [0 1 1 ... 1 1 0]\n",
      " [1 1 1 ... 1 1 1]\n",
      " [1 1 1 ... 1 1 1]]\n",
      "origin y_true.shape=(8, 256)\n",
      "(8,)\n",
      "filtered y_true.shape=(8, 256)\n",
      "non-padding ratio: 8/8=1.0\n",
      "\n",
      "{'accuracy': 3.46875, 'recall': 0, 'precision': 0, 'f1': 0}\n"
     ]
    }
   ],
   "source": [
    "seq_len = 12\n",
    "pad_seq_len = 4 \n",
    "y_true = torch.randint(0,2,(4,8,32,8)).numpy()\n",
    "y_pred = torch.randint(0,2,(4,8,32,8)).numpy()\n",
    "print(acc_precision_recall_f1(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = {\n",
    "    \"auto_categorization\": 328,\n",
    "    \"tense\": 286,\n",
    "    \"disfl_qa\": 8000,\n",
    "    \"semantic_parsing_in_context_sparc\": 1160,\n",
    "    \"word_sorting\": 1900,\n",
    "    \"linguistics_puzzles\": 2000,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto_categorization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nus-hx/.conda/envs/moe/lib/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for tasksource/bigbench contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/tasksource/bigbench\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tense\n",
      "disfl_qa\n",
      "semantic_parsing_in_context_sparc\n",
      "word_sorting\n",
      "linguistics_puzzles\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "dataset_name = \"tasksource/bigbench\"\n",
    "# names = datasets.get_dataset_config_names(dataset_name)\n",
    "\n",
    "names = list(dataset_names.keys())\n",
    "all_inputs = []\n",
    "for name in names:\n",
    "    print(name)\n",
    "    all_inputs.append(datasets.load_dataset(dataset_name, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['inputs', 'targets', 'multiple_choice_targets', 'multiple_choice_scores', 'idx'],\n",
       "        num_rows: 263\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['inputs', 'targets', 'multiple_choice_targets', 'multiple_choice_scores', 'idx'],\n",
       "        num_rows: 65\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10936, 2733)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_all_inputs = []\n",
    "valid_all_inputs = []\n",
    "for dataset in all_inputs:\n",
    "    train_all_inputs += [text for text in dataset[\"train\"][\"inputs\"]]\n",
    "    valid_all_inputs += [text for text in dataset[\"validation\"][\"inputs\"]]\n",
    "len(train_all_inputs), len(valid_all_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
